{"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XF2omTACEOrK","executionInfo":{"status":"ok","timestamp":1657968545100,"user_tz":-120,"elapsed":47256,"user":{"displayName":"Gehad Refaai","userId":"10404173014734954760"}},"outputId":"48b44c58-a1b6-4e67-d5e0-3be4e0b0b8a9"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Tqd-shv2A6n_"},"outputs":[],"source":["import tensorflow as tf\n","import dlib\n","import cv2\n","import os\n","import numpy as np\n","from PIL import Image, ImageChops, ImageEnhance\n","from tensorflow.keras.models import load_model\n","from tensorflow.keras.preprocessing.image import img_to_array, load_img\n","import statistics\n","from statistics import mode"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":36},"id":"ZbgOwt6lA6oB","executionInfo":{"status":"ok","timestamp":1657921432456,"user_tz":-120,"elapsed":450,"user":{"displayName":"Gehad Refaai","userId":"10404173014734954760"}},"outputId":"9fa85ffc-52a8-4bc8-f650-998ddcef21b3"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["'2.8.2'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":19}],"source":["tf.__version__"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"y4KaoTqXA6oC"},"outputs":[],"source":["model = load_model('/content/drive/MyDrive/Graduation project/deepfake-detection-modelv2.h5')"]},{"cell_type":"code","source":["model.summary()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_souDf-zq8-S","executionInfo":{"status":"ok","timestamp":1657915504390,"user_tz":-120,"elapsed":8,"user":{"displayName":"Gehad Refaai","userId":"10404173014734954760"}},"outputId":"39671390-ba5a-4fa0-8c2a-979d08929808"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," inception_resnet_v2 (Functi  (None, 5, 5, 1536)       54336736  \n"," onal)                                                           \n","                                                                 \n"," global_average_pooling2d (G  (None, 1536)             0         \n"," lobalAveragePooling2D)                                          \n","                                                                 \n"," dense (Dense)               (None, 2)                 3074      \n","                                                                 \n","=================================================================\n","Total params: 54,339,810\n","Trainable params: 54,279,266\n","Non-trainable params: 60,544\n","_________________________________________________________________\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Qki4jFjxA6oD","executionInfo":{"status":"ok","timestamp":1657922638316,"user_tz":-120,"elapsed":118372,"user":{"displayName":"Gehad Refaai","userId":"10404173014734954760"}},"outputId":"33968b8d-3e3d-4383-812a-d3abb70abe5b"},"outputs":[{"output_type":"stream","name":"stdout","text":["0\n"]}],"source":["input_shape = (224, 224, 3)\n","pr_data = []\n","detector = dlib.get_frontal_face_detector()\n","cap = cv2.VideoCapture('/content/drive/MyDrive/Graduation project/kaggle/test_videos/adohdulfwb.mp4')\n","frameRate = cap.get(5)\n","res=[]\n","while cap.isOpened():\n","    frameId = cap.get(1)\n","    ret, frame = cap.read()\n","    \n","    if ret != True:\n","        break\n","    if frameId % 2 == 0:\n","        face_rects, scores, idx = detector.run(frame, 0)\n","        for i, d in enumerate(face_rects):\n","            x1 = d.left()\n","            y1 = d.top()\n","            x2 = d.right()\n","            y2 = d.bottom()\n","            crop_img = frame[y1:y2, x1:x2]\n","            data = img_to_array(cv2.resize(crop_img, (224, 224))).flatten() / 255.0\n","            data = data.reshape(-1, 224, 224, 3)\n","            #print(model.predict(data)[0][0])\n","            res.append(round(model.predict(data)[0][0]))\n","            #res.append((model.predict(data) > 0.5).astype(\"int32\"))\n","\n","print(mode(res))"]}],"metadata":{"kernelspec":{"display_name":"Python [conda env:root] *","language":"python","name":"conda-root-py"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.4"},"colab":{"name":"Prediction.ipynb","provenance":[]}},"nbformat":4,"nbformat_minor":0}